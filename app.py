import streamlit as st
from ultralytics import YOLO
from PIL import Image
import cv2
import tempfile
import time
from pathlib import Path
from collections import Counter

# Configuration de la page
st.set_page_config(
    page_title="YOLOv8 - Exploration IA",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Styles CSS personnalisÃ©s pour un look "Premium"
st.markdown("""
    <style>
    .main {
        background-color: #0e1117;
    }
    .stButton>button {
        width: 100%;
        border-radius: 5px;
        height: 3em;
        background-color: #ff4b4b;
        color: white;
    }
    .stButton>button:hover {
        background-color: #ff3333;
        border-color: #ff3333;
    }
    h1 {
        color: #fafafa;
    }
    h2, h3 {
        color: #e0e0e0;
    }
    .report-box {
        background-color: #262730;
        padding: 20px;
        border-radius: 10px;
        border: 1px solid #4c4c4c;
    }
    </style>
    """, unsafe_allow_html=True)

# Chargement du modÃ¨le (mis en cache pour la performance)
@st.cache_resource
def load_model():
    return YOLO("yolov8n.pt")

try:
    model = load_model()
except Exception as e:
    st.error(f"Erreur lors du chargement du modÃ¨le : {e}")
    st.stop()

# Titre et Introduction
st.title("ğŸ¤– Projet 3 : Exploration IA avec YOLOv8")
st.markdown("### DÃ©tection d'objets en temps rÃ©el")
st.markdown("---")

# Sidebar pour la navigation
st.sidebar.title("Navigation")
mode = st.sidebar.radio("Choisir le mode :", ["ğŸ–¼ï¸ Image", "ğŸ¬ VidÃ©o", "ğŸ“· Webcam"])

st.sidebar.markdown("---")
st.sidebar.info(
    "Ce projet explore l'utilisation de l'IA pour la vision par ordinateur. "
    "Il utilise le modÃ¨le **YOLOv8** pour dÃ©tecter des objets dans des images, vidÃ©os et flux webcam."
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MODE IMAGE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if mode == "ğŸ–¼ï¸ Image":
    st.header("DÃ©tection sur Image")
    
    uploaded_file = st.file_uploader("Choisissez une image...", type=['jpg', 'jpeg', 'png', 'bmp'])
    
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption="Image originale", use_container_width=True)
        
        if st.button("Lancer la dÃ©tection"):
            with st.spinner("Analyse en cours..."):
                results = model(image)
                res = results[0]
                annotated_img = res.plot()
                st.image(annotated_img, caption="RÃ©sultat de la dÃ©tection", use_container_width=True)
                
                # Affichage des rÃ©sultats sous l'image
                st.markdown("### ğŸ“‹ RÃ©sultats de la dÃ©tection")
                boxes = res.boxes
                if boxes:
                    class_counts = Counter()
                    names = res.names
                    
                    # Collecter les objets dÃ©tectÃ©s
                    detected_items = []
                    for cls_id, conf in zip(boxes.cls.tolist(), boxes.conf.tolist()):
                        class_name = names[int(cls_id)]
                        class_counts[class_name] += 1
                        detected_items.append(f"{class_name} ({conf:.2f})")
                    
                    # Afficher le rÃ©sumÃ©
                    st.success(f"Objets dÃ©tectÃ©s : {len(boxes)}")
                    
                    # Afficher le dÃ©tail
                    st.markdown("**DÃ©tails :**")
                    st.write(", ".join(detected_items))
                    
                    # Afficher le comptage par classe
                    st.markdown("**RÃ©sumÃ© par classe :**")
                    col_metrics = st.columns(len(class_counts))
                    for idx, (name, count) in enumerate(class_counts.items()):
                        with col_metrics[idx % len(col_metrics)]:
                            st.metric(label=name, value=count)
                else:
                    st.warning("Aucun objet dÃ©tectÃ©.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MODE VIDÃ‰O
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif mode == "ğŸ¬ VidÃ©o":
    st.header("DÃ©tection sur VidÃ©o")
    
    uploaded_video = st.file_uploader("Choisissez une vidÃ©o...", type=['mp4', 'mov', 'avi', 'mkv'])
    
    if uploaded_video is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_video.read())
        video_path = tfile.name
        
        st.video(video_path)
        
        if st.button("Analyser la vidÃ©o"):
            st.warning("L'analyse vidÃ©o peut prendre du temps...")
            
            st_frame = st.empty()
            st_results = st.empty() # Placeholder pour les rÃ©sultats sous la vidÃ©o
            
            cap = cv2.VideoCapture(video_path)
            
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                
                results = model(frame)
                res = results[0]
                annotated_frame = res.plot()
                
                # Convertir BGR vers RGB
                frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                st_frame.image(frame_rgb, caption="Traitement en cours...", use_container_width=True)
                
                # Afficher les rÃ©sultats du frame courant sous la vidÃ©o
                boxes = res.boxes
                if boxes:
                    names = res.names
                    detected_in_frame = [f"{names[int(c)]}" for c in boxes.cls.tolist()]
                    counts = Counter(detected_in_frame)
                    summary = ", ".join([f"{k}: {v}" for k, v in counts.items()])
                    st_results.info(f"**DÃ©tectÃ© dans ce cadre :** {summary}")
                else:
                    st_results.info("Rien dÃ©tectÃ© dans ce cadre.")
            
            cap.release()
            st.success("Analyse terminÃ©e !")
            
            # Nettoyage du fichier temporaire
            try:
                import os
                os.unlink(video_path)
            except Exception as e:
                print(f"Erreur lors de la suppression du fichier temporaire : {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MODE WEBCAM
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif mode == "ğŸ“· Webcam":
    st.header("DÃ©tection Webcam en Temps RÃ©el")
    
    run = st.checkbox('DÃ©marrer la Webcam')
    FRAME_WINDOW = st.image([])
    RESULTS_WINDOW = st.empty() # Placeholder pour les rÃ©sultats
    
    if run:
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            st.error("Impossible d'accÃ©der Ã  la webcam.")
        else:
            while run:
                ret, frame = cap.read()
                if not ret:
                    st.error("Erreur de lecture du flux webcam.")
                    break
                
                results = model(frame)
                res = results[0]
                annotated_frame = res.plot()
                
                frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                FRAME_WINDOW.image(frame_rgb)
                
                # Afficher les rÃ©sultats sous la webcam
                boxes = res.boxes
                if boxes:
                    names = res.names
                    detected_in_frame = [f"{names[int(c)]}" for c in boxes.cls.tolist()]
                    counts = Counter(detected_in_frame)
                    summary = ", ".join([f"{k}: {v}" for k, v in counts.items()])
                    RESULTS_WINDOW.info(f"**DÃ©tectÃ© :** {summary}")
                else:
                    RESULTS_WINDOW.info("Rien dÃ©tectÃ©.")
            
            cap.release()
    else:
        st.info("Cochez la case ci-dessus pour activer la webcam.")

# Footer
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #666;'>"
    "Projet rÃ©alisÃ© dans le cadre du cours 'Explorer une technologie avec l'IA'.<br>"
    "PropulsÃ© par YOLOv8 et Streamlit."
    "</div>",
    unsafe_allow_html=True
)

if __name__ == "__main__":
    import sys
    import subprocess
    import os
    
    # Ã‰vite la rÃ©cursion infinie : si on a dÃ©jÃ  lancÃ© le sous-processus, on ne fait rien
    if not os.environ.get("STREAMLIT_FROM_SUBPROCESS"):
        # On prÃ©pare l'environnement avec le flag
        env = os.environ.copy()
        env["STREAMLIT_FROM_SUBPROCESS"] = "true"
        
        # On lance streamlit dans un processus sÃ©parÃ©
        # sys.executable assure qu'on utilise le mÃªme python
        subprocess.run([sys.executable, "-m", "streamlit", "run", sys.argv[0]], env=env)
        sys.exit(0)
